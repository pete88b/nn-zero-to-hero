{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff13fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4176c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_balanced(text):\n",
    "    text = text.strip()\n",
    "    n_open, n_closed = 0, 0\n",
    "    for s in text:\n",
    "        if s == '(':\n",
    "            n_open += 1\n",
    "        if s == ')':\n",
    "            n_closed += 1\n",
    "        if n_closed > n_open:\n",
    "            return False\n",
    "    if n_open > n_closed:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19821b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_balanced('(())()')\n",
    "assert is_balanced('()')\n",
    "assert is_balanced('') # arbitrary choice to say empty string is balanced\n",
    "assert not is_balanced(')(')\n",
    "assert not is_balanced('(())(')\n",
    "assert not is_balanced('(()()')\n",
    "assert not is_balanced('(()))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5b7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example(length=10):\n",
    "    assert length % 2 == 0\n",
    "    n_open, n_closed = 0, 0\n",
    "    result = ''\n",
    "    for _ in range(length):\n",
    "        if n_open >= length // 2:\n",
    "            result += ')'\n",
    "            n_closed += 1\n",
    "        elif n_open > n_closed:\n",
    "            s = random.choice('()')\n",
    "            if s == '(':\n",
    "                n_open += 1\n",
    "            if s == ')':\n",
    "                n_closed += 1\n",
    "            result += s\n",
    "        else:\n",
    "            result += '('\n",
    "            n_open += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad35fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((()))))\n",
      "(((()()())))\n",
      "()((()()()()))\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    ex = generate_example(10 + i * 2)\n",
    "    assert is_balanced(ex)\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178ab75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'w') as f:\n",
    "    f.write('\\n'.join([generate_example(random.randint(5, 10) * 2) for _ in range(50000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6071a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()()((())()(()))\\n()()()(())((()))\\n(((())(()(()))))\\n((((((((()))))))))\\n(((()(()))(())))\\n(())((((((()('"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c098d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b289e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d9a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58108e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a38428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f20e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95392c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e769f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4937e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91626bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperparameters\n",
    "# batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "# block_size = 256 # what is the maximum context length for predictions?\n",
    "# max_iters = 5000\n",
    "# eval_interval = 500\n",
    "# learning_rate = 3e-4\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# eval_iters = 200\n",
    "# n_embd = 384\n",
    "# n_head = 6\n",
    "# n_layer = 6\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8553a0",
   "metadata": {},
   "source": [
    "reduce the block size to be a bit larger than the largest sample we train/test with - this means that the model can see the complete examle\n",
    "\n",
    "reduce embedding size, number of heads and layers to make the model smaller - faster to train\n",
    "\n",
    "large batch size also makes training faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d12f019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051715 M parameters\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "f = 10 # increase batch size and reduce iterations by this ammount\n",
    "batch_size = int(64*f) # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions? \n",
    "max_iters = int(5000/f)\n",
    "eval_interval = int(500/f)\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = int(200/f)\n",
    "n_embd = 32\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "model = GPT()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "016a9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051715 M parameters\n",
      "step 0: train loss 1.2791, val loss 1.2784\n",
      "step 50: train loss 0.8281, val loss 0.8280\n",
      "step 100: train loss 0.8006, val loss 0.8004\n",
      "step 150: train loss 0.7837, val loss 0.7836\n",
      "step 200: train loss 0.7597, val loss 0.7598\n",
      "step 250: train loss 0.7250, val loss 0.7245\n",
      "step 300: train loss 0.6958, val loss 0.6959\n",
      "step 350: train loss 0.6767, val loss 0.6781\n",
      "step 400: train loss 0.6624, val loss 0.6614\n",
      "step 450: train loss 0.6481, val loss 0.6489\n",
      "step 499: train loss 0.6363, val loss 0.6357\n"
     ]
    }
   ],
   "source": [
    "model = GPT()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'gpt_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1511c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(torch.tensor(lossi).view(-1, 10).mean(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "935846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(f='gpt_0.pt', max_new_tokens=500):\n",
    "    model = GPT()\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    model.eval().to(device)\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    # print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "    with torch.no_grad():\n",
    "        return decode(model.generate(context, max_new_tokens=max_new_tokens)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf89e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(((()())()))()()\\n()(((((())(()))\\n(()))()((()))))\\n()(()((()))()\\n((())()))()\\n(()((())()(((())))\\n((()))((()))\\n()()(\\n())(()((()((()))))\\n(()()()))((((()))))\\n())\\n()()(()())((())))()(()\\n()()(()())()()\\n\\n()(()(((())(()((\\n((())(()()(()))))))))\\n()(()(((()(()))\\n()(())((())))\\n((()()()()((()(())()))()\\n)(()())\\n(()()(()())((((())))())\\n(((())))))\\n()()((((())()\\n()()(()))()(())\\n()(())()()(())((()(())))()\\n()((())(((()))))\\n(()))()()()()()\\n(()()()\\n\\n()()(()())())(()(())(())\\n((((()))))\\n()(()(()(((())()))\\n()((()())(())('"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sample = generate_sample()\n",
    "generated_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699052b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_balanced(text):\n",
    "    text = text.strip()\n",
    "    n_open, n_closed = 0, 0\n",
    "    for i, s in enumerate(text):\n",
    "        if s == '(':\n",
    "            n_open += 1\n",
    "        if s == ')':\n",
    "            n_closed += 1\n",
    "        if n_closed > n_open:\n",
    "            return False, i, 'early close'\n",
    "    if n_open > n_closed:\n",
    "        return False, f'{n_open=} {n_closed=}'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "844143cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "True ()()()(())\n",
      "(False, 'n_open=8 n_closed=7') (()(((())(())))\n",
      "(False, 6, 'early close') (())()))(()\n",
      "(False, 22, 'early close') ((()(())(()))(()())()))\n",
      "(False, 'n_open=9 n_closed=7') ()(()(()))()((()\n",
      "(False, 2, 'early close') ()))()()()(()())\n",
      "(False, 20, 'early close') ()(()()()(()(()()))))\n",
      "True ((((()))()))\n",
      "True ()((()())((((())))))\n",
      "True (())()()((())(()()))\n",
      "True ((())(())())\n",
      "True (()(()))()()\n",
      "(False, 16, 'early close') ((()()((())))()))\n",
      "True (((())()()))\n",
      "(False, 14, 'early close') ()()()(())()())((()\n",
      "(False, 8, 'early close') (())()()))\n",
      "(False, 16, 'early close') ()((()(()))(())))\n",
      "(False, 'n_open=8 n_closed=7') ()((()))((()())\n",
      "True ()(()())()((()))()\n",
      "True ()(())()(())\n",
      "True (((()()((()))))())\n",
      "(False, 'n_open=8 n_closed=7') (()(()(()(())))\n",
      "(False, 14, 'early close') ()((((())))()))\n",
      "True ((()(()())(())))\n",
      "True ()\n",
      "(False, 'n_open=10 n_closed=9') ()(()(()()(())()())\n",
      "(False, 'n_open=7 n_closed=5') ()()((()(())\n",
      "(False, 4, 'early close') ()()))()(()())((((()))\n",
      "(False, 6, 'early close') (())())((()(())))())\n",
      "(False, 8, 'early close') ()(())())(())())\n",
      "(False, 'n_open=5 n_closed=2') (()(()(\n"
     ]
    }
   ],
   "source": [
    "for sample in generated_sample.split('\\n'):\n",
    "    print(_is_balanced(sample), sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07337601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_as_df(f='gpt_0.pt', max_new_tokens=50):\n",
    "    model = GPT()\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    model.eval().to(device)\n",
    "    idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    data = []\n",
    "    text = ''\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crop idx to the last block_size tokens\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        # get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(idx_cond)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :] # becomes (B, C)\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "        char_next = decode([idx_next.item()])\n",
    "        text += char_next\n",
    "        if '\\n' == char_next:\n",
    "            text = ''\n",
    "            balanced = ''\n",
    "        else:\n",
    "            balanced = _is_balanced(text)\n",
    "        data.append({\n",
    "            'end': probs[0][0].item(),\n",
    "            '(': probs[0][1].item(),\n",
    "            ')': probs[0][2].item(),\n",
    "            'char': char_next, \n",
    "            'balanced': balanced,\n",
    "            'text': text,\n",
    "            'len': len(text),\n",
    "    #         'idx_next': idx_next.item()\n",
    "        })\n",
    "        # append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fcee448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>char</th>\n",
       "      <th>balanced</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.978812</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.934429</td>\n",
       "      <td>0.054604</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)(</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.627020</td>\n",
       "      <td>0.370542</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.909389</td>\n",
       "      <td>0.073867</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.552460</td>\n",
       "      <td>0.445080</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()((</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.525469</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.679378</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()(</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.429830</td>\n",
       "      <td>0.567605</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.411337</td>\n",
       "      <td>0.586016</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()(((</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.390460</td>\n",
       "      <td>0.606986</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((()</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.254342</td>\n",
       "      <td>0.742957</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.720221</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())(</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.370833</td>\n",
       "      <td>0.626515</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.206929</td>\n",
       "      <td>0.778932</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())())</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.203596</td>\n",
       "      <td>0.311272</td>\n",
       "      <td>0.485133</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.544138</td>\n",
       "      <td>0.279314</td>\n",
       "      <td>0.176547</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.361679</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))((</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.358408</td>\n",
       "      <td>0.638924</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(((</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.657943</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))((((</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.329208</td>\n",
       "      <td>0.667996</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(((()</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.099236</td>\n",
       "      <td>0.878766</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(((())</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.115919</td>\n",
       "      <td>0.800857</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(((()))</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.376353</td>\n",
       "      <td>0.142047</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 0, early close)</td>\n",
       "      <td>)()(()((())()))(((())))</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.748732</td>\n",
       "      <td>0.096135</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.987811</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.449932</td>\n",
       "      <td>0.546695</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.023880</td>\n",
       "      <td>0.886672</td>\n",
       "      <td>0.089448</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=1)</td>\n",
       "      <td>()(</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.438303</td>\n",
       "      <td>0.558802</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()()</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.878032</td>\n",
       "      <td>0.107133</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=3 n_closed=2)</td>\n",
       "      <td>()()(</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.409882</td>\n",
       "      <td>0.586271</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=4 n_closed=2)</td>\n",
       "      <td>()()((</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.421374</td>\n",
       "      <td>0.575821</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=4 n_closed=3)</td>\n",
       "      <td>()()(()</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.380752</td>\n",
       "      <td>0.594685</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()()(())</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.714080</td>\n",
       "      <td>0.265557</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=5 n_closed=4)</td>\n",
       "      <td>()()(())(</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.406369</td>\n",
       "      <td>0.590913</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()()(())()</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.238790</td>\n",
       "      <td>0.612582</td>\n",
       "      <td>0.148628</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.987496</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.461832</td>\n",
       "      <td>0.535339</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=0)</td>\n",
       "      <td>((</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.461417</td>\n",
       "      <td>0.535680</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=2 n_closed=1)</td>\n",
       "      <td>(()</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.651451</td>\n",
       "      <td>0.335481</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.892866</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=3 n_closed=2)</td>\n",
       "      <td>(())(</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.441651</td>\n",
       "      <td>0.555614</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=4 n_closed=2)</td>\n",
       "      <td>(())((</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.463322</td>\n",
       "      <td>0.533711</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=5 n_closed=2)</td>\n",
       "      <td>(())(((</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.434774</td>\n",
       "      <td>0.562332</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=5 n_closed=3)</td>\n",
       "      <td>(())((()</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.524270</td>\n",
       "      <td>0.470062</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=6 n_closed=3)</td>\n",
       "      <td>(())((()(</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.432785</td>\n",
       "      <td>0.564340</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=6 n_closed=4)</td>\n",
       "      <td>(())((()()</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.485377</td>\n",
       "      <td>0.499472</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=6 n_closed=5)</td>\n",
       "      <td>(())((()())</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.481652</td>\n",
       "      <td>0.482698</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=7 n_closed=5)</td>\n",
       "      <td>(())((()())(</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.417851</td>\n",
       "      <td>0.579359</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=7 n_closed=6)</td>\n",
       "      <td>(())((()())()</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.045871</td>\n",
       "      <td>0.363512</td>\n",
       "      <td>0.590616</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())((()())())</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.215542</td>\n",
       "      <td>0.516326</td>\n",
       "      <td>0.268133</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         end         (         ) char                      balanced   \n",
       "0   0.002552  0.978812  0.018636    )       (False, 0, early close)  \\\n",
       "1   0.010967  0.934429  0.054604    (       (False, 0, early close)   \n",
       "2   0.002438  0.627020  0.370542    )       (False, 0, early close)   \n",
       "3   0.016744  0.909389  0.073867    (       (False, 0, early close)   \n",
       "4   0.002459  0.552460  0.445080    (       (False, 0, early close)   \n",
       "5   0.002783  0.471748  0.525469    )       (False, 0, early close)   \n",
       "6   0.004340  0.679378  0.316282    (       (False, 0, early close)   \n",
       "7   0.002565  0.429830  0.567605    (       (False, 0, early close)   \n",
       "8   0.002647  0.411337  0.586016    (       (False, 0, early close)   \n",
       "9   0.002554  0.390460  0.606986    )       (False, 0, early close)   \n",
       "10  0.002700  0.254342  0.742957    )       (False, 0, early close)   \n",
       "11  0.006554  0.273224  0.720221    (       (False, 0, early close)   \n",
       "12  0.002652  0.370833  0.626515    )       (False, 0, early close)   \n",
       "13  0.014140  0.206929  0.778932    )       (False, 0, early close)   \n",
       "14  0.203596  0.311272  0.485133    )       (False, 0, early close)   \n",
       "15  0.544138  0.279314  0.176547    (       (False, 0, early close)   \n",
       "16  0.002693  0.361679  0.635628    (       (False, 0, early close)   \n",
       "17  0.002668  0.358408  0.638924    (       (False, 0, early close)   \n",
       "18  0.002953  0.339105  0.657943    (       (False, 0, early close)   \n",
       "19  0.002796  0.329208  0.667996    )       (False, 0, early close)   \n",
       "20  0.021999  0.099236  0.878766    )       (False, 0, early close)   \n",
       "21  0.083224  0.115919  0.800857    )       (False, 0, early close)   \n",
       "22  0.376353  0.142047  0.481600    )       (False, 0, early close)   \n",
       "23  0.748732  0.096135  0.155134   \\n                                 \n",
       "24  0.006743  0.987811  0.005446    (  (False, n_open=1 n_closed=0)   \n",
       "25  0.003372  0.449932  0.546695    )                          True   \n",
       "26  0.023880  0.886672  0.089448    (  (False, n_open=2 n_closed=1)   \n",
       "27  0.002895  0.438303  0.558802    )                          True   \n",
       "28  0.014836  0.878032  0.107133    (  (False, n_open=3 n_closed=2)   \n",
       "29  0.003847  0.409882  0.586271    (  (False, n_open=4 n_closed=2)   \n",
       "30  0.002805  0.421374  0.575821    )  (False, n_open=4 n_closed=3)   \n",
       "31  0.024563  0.380752  0.594685    )                          True   \n",
       "32  0.020363  0.714080  0.265557    (  (False, n_open=5 n_closed=4)   \n",
       "33  0.002719  0.406369  0.590913    )                          True   \n",
       "34  0.238790  0.612582  0.148628   \\n                                 \n",
       "35  0.004964  0.987496  0.007540    (  (False, n_open=1 n_closed=0)   \n",
       "36  0.002828  0.461832  0.535339    (  (False, n_open=2 n_closed=0)   \n",
       "37  0.002903  0.461417  0.535680    )  (False, n_open=2 n_closed=1)   \n",
       "38  0.013068  0.651451  0.335481    )                          True   \n",
       "39  0.008400  0.892866  0.098734    (  (False, n_open=3 n_closed=2)   \n",
       "40  0.002735  0.441651  0.555614    (  (False, n_open=4 n_closed=2)   \n",
       "41  0.002967  0.463322  0.533711    (  (False, n_open=5 n_closed=2)   \n",
       "42  0.002894  0.434774  0.562332    )  (False, n_open=5 n_closed=3)   \n",
       "43  0.005669  0.524270  0.470062    (  (False, n_open=6 n_closed=3)   \n",
       "44  0.002876  0.432785  0.564340    )  (False, n_open=6 n_closed=4)   \n",
       "45  0.015151  0.485377  0.499472    )  (False, n_open=6 n_closed=5)   \n",
       "46  0.035650  0.481652  0.482698    (  (False, n_open=7 n_closed=5)   \n",
       "47  0.002790  0.417851  0.579359    )  (False, n_open=7 n_closed=6)   \n",
       "48  0.045871  0.363512  0.590616    )                          True   \n",
       "49  0.215542  0.516326  0.268133   \\n                                 \n",
       "\n",
       "                       text  len  \n",
       "0                         )    1  \n",
       "1                        )(    2  \n",
       "2                       )()    3  \n",
       "3                      )()(    4  \n",
       "4                     )()((    5  \n",
       "5                    )()(()    6  \n",
       "6                   )()(()(    7  \n",
       "7                  )()(()((    8  \n",
       "8                 )()(()(((    9  \n",
       "9                )()(()((()   10  \n",
       "10              )()(()((())   11  \n",
       "11             )()(()((())(   12  \n",
       "12            )()(()((())()   13  \n",
       "13           )()(()((())())   14  \n",
       "14          )()(()((())()))   15  \n",
       "15         )()(()((())()))(   16  \n",
       "16        )()(()((())()))((   17  \n",
       "17       )()(()((())()))(((   18  \n",
       "18      )()(()((())()))((((   19  \n",
       "19     )()(()((())()))(((()   20  \n",
       "20    )()(()((())()))(((())   21  \n",
       "21   )()(()((())()))(((()))   22  \n",
       "22  )()(()((())()))(((())))   23  \n",
       "23                             0  \n",
       "24                        (    1  \n",
       "25                       ()    2  \n",
       "26                      ()(    3  \n",
       "27                     ()()    4  \n",
       "28                    ()()(    5  \n",
       "29                   ()()((    6  \n",
       "30                  ()()(()    7  \n",
       "31                 ()()(())    8  \n",
       "32                ()()(())(    9  \n",
       "33               ()()(())()   10  \n",
       "34                             0  \n",
       "35                        (    1  \n",
       "36                       ((    2  \n",
       "37                      (()    3  \n",
       "38                     (())    4  \n",
       "39                    (())(    5  \n",
       "40                   (())((    6  \n",
       "41                  (())(((    7  \n",
       "42                 (())((()    8  \n",
       "43                (())((()(    9  \n",
       "44               (())((()()   10  \n",
       "45              (())((()())   11  \n",
       "46             (())((()())(   12  \n",
       "47            (())((()())()   13  \n",
       "48           (())((()())())   14  \n",
       "49                             0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd20cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probs(context='\\n', f='gpt_0.pt', max_new_tokens=50):\n",
    "    model = GPT()\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    model.eval().to(device)\n",
    "    @torch.no_grad()\n",
    "    def _dump(c):\n",
    "        print(c.replace('\\n', '\\\\n'), encode(c))\n",
    "        c = torch.tensor([encode(c)], dtype=torch.long, device=device)\n",
    "        logits, _ = model(c)\n",
    "    #     print(logits)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "        print(probs[0], '\\n')\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    _dump(context)\n",
    "    for i in ['\\n', '(', ')']:\n",
    "        _dump(i + context)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ce5a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\\n [0]\n",
      "tensor([0.0026, 0.9788, 0.0186], device='cuda:0') \n",
      "\n",
      "\\n\\n [0, 0]\n",
      "tensor([0.0024, 0.9807, 0.0169], device='cuda:0') \n",
      "\n",
      "(\\n [1, 0]\n",
      "tensor([0.0020, 0.8932, 0.1047], device='cuda:0') \n",
      "\n",
      ")\\n [2, 0]\n",
      "tensor([0.0037, 0.9748, 0.0215], device='cuda:0') \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\\n( [0, 1]\n",
      "tensor([0.0024, 0.6156, 0.3819], device='cuda:0') \n",
      "\n",
      "\\n\\n( [0, 0, 1]\n",
      "tensor([0.0023, 0.7020, 0.2957], device='cuda:0') \n",
      "\n",
      "(\\n( [1, 0, 1]\n",
      "tensor([0.0024, 0.5320, 0.4656], device='cuda:0') \n",
      "\n",
      ")\\n( [2, 0, 1]\n",
      "tensor([0.0025, 0.5969, 0.4006], device='cuda:0') \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\\n() [0, 1, 2]\n",
      "tensor([0.0053, 0.8960, 0.0987], device='cuda:0') \n",
      "\n",
      "\\n\\n() [0, 0, 1, 2]\n",
      "tensor([0.0045, 0.9399, 0.0556], device='cuda:0') \n",
      "\n",
      "(\\n() [1, 0, 1, 2]\n",
      "tensor([0.0056, 0.7697, 0.2247], device='cuda:0') \n",
      "\n",
      ")\\n() [2, 0, 1, 2]\n",
      "tensor([0.0086, 0.9037, 0.0878], device='cuda:0') \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\\n(())()(()) [0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2]\n",
      "tensor([0.0813, 0.6950, 0.2236], device='cuda:0') \n",
      "\n",
      "\\n\\n(())()(()) [0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2]\n",
      "tensor([0.0427, 0.8645, 0.0927], device='cuda:0') \n",
      "\n",
      "(\\n(())()(()) [1, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2]\n",
      "tensor([0.1247, 0.4744, 0.4009], device='cuda:0') \n",
      "\n",
      ")\\n(())()(()) [2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2]\n",
      "tensor([0.2272, 0.5784, 0.1945], device='cuda:0') \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for context in ['\\n', '\\n(', '\\n()', '\\n(())()(())']:\n",
    "    print_probs(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f3545",
   "metadata": {},
   "source": [
    "# policy gradient ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a6ba68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_partial_example():\n",
    "    \"Generate an example that can be terminated as-is or made valid by adding more parens\"\n",
    "    length = random.randint(5, 10) * 2\n",
    "    stop = random.randint(0, length)\n",
    "    n_open, n_closed = 0, 0\n",
    "    result = [0]\n",
    "    for i in range(length):\n",
    "        if i == stop:\n",
    "            return result\n",
    "        if n_open >= length // 2:\n",
    "            n_closed += 1\n",
    "            result.append(2)\n",
    "        elif n_open > n_closed:\n",
    "            s = random.choice('()')\n",
    "            if s == '(':\n",
    "                n_open += 1\n",
    "                result.append(1)\n",
    "            if s == ')':\n",
    "                n_closed += 1\n",
    "                result.append(2)\n",
    "        else:\n",
    "            n_open += 1\n",
    "            result.append(1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60633721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(('"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(generate_partial_example())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b19e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def _context_as_tensor(self):\n",
    "        return torch.tensor([self.context[-block_size:]], dtype=torch.long, device=device)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.context = generate_partial_example() # [0] use partial examples so we're not always starting from nothing\n",
    "        return self._context_as_tensor()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.context.append(action)\n",
    "        if action == 0:\n",
    "            done = True\n",
    "            rew = 10 if is_balanced(decode(self.context)) else 0\n",
    "        else:\n",
    "            done = False\n",
    "            rew = 0\n",
    "#         return obs, rew, done, _\n",
    "        return self._context_as_tensor(), rew, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96528883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make loss function whose gradient, for the right data, is policy gradient\n",
    "def compute_loss(logits, act, weights):\n",
    "    policy = torch.distributions.categorical.Categorical(logits=logits)\n",
    "    logp = policy.log_prob(act)\n",
    "    return -(logp * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55343dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: 2.527 \t return: 3.920 \t ep_len: 10.060\n",
      "epoch:   1 \t loss: 2.468 \t return: 4.200 \t ep_len: 10.070\n",
      "epoch:   2 \t loss: 2.132 \t return: 3.886 \t ep_len: 9.507\n",
      "epoch:   3 \t loss: 2.251 \t return: 4.123 \t ep_len: 8.794\n",
      "epoch:   4 \t loss: 2.861 \t return: 5.145 \t ep_len: 8.324\n"
     ]
    }
   ],
   "source": [
    "model = GPT()\n",
    "model.load_state_dict(torch.load('gpt_0.pt'))\n",
    "model.to(device)\n",
    "# batch_size=5000\n",
    "batch_size=2000 # TODO: 5000 is really slow - but we need large batch size to reduce variance\n",
    "env = Environment()\n",
    "# make optimizer\n",
    "# optimizer = Adam(logits_net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# for training policy\n",
    "for i in range(5):\n",
    "    # make some empty lists for logging.\n",
    "    batch_obs = []          # for observations\n",
    "    batch_logits = []\n",
    "    batch_acts = []         # for actions\n",
    "    batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "    batch_rets = []         # for measuring episode returns\n",
    "    batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "    # reset episode-specific variables\n",
    "    obs = env.reset()       # first obs comes from starting distribution\n",
    "    done = False            # signal from environment that episode is over\n",
    "    ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "    # collect experience by acting in the environment with current policy\n",
    "    while True:\n",
    "        # act in the environment\n",
    "        logits, _ = model(obs)\n",
    "        logits = logits[:, -1, :][0]\n",
    "        policy = torch.distributions.categorical.Categorical(logits=logits)\n",
    "        act = policy.sample().item()\n",
    "        obs, rew, done, _ = env.step(act)\n",
    "\n",
    "        # save observation, logits, action, reward\n",
    "        batch_obs.append(obs)\n",
    "        batch_logits.append(logits)\n",
    "        batch_acts.append(act)\n",
    "        ep_rews.append(rew)\n",
    "\n",
    "        if done:\n",
    "            # if episode is over, record info about episode\n",
    "            ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "            batch_rets.append(ep_ret)\n",
    "            batch_lens.append(ep_len)\n",
    "\n",
    "            # the weight for each logprob(a|s) is R(tau)\n",
    "            batch_weights += [ep_ret] * ep_len\n",
    "\n",
    "            # reset episode-specific variables\n",
    "            obs, done, ep_rews = env.reset(), False, []\n",
    "\n",
    "            # end experience loop if we have enough of it\n",
    "            if len(batch_obs) > batch_size:\n",
    "                break\n",
    "\n",
    "    # take a single policy gradient update step\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss = compute_loss(\n",
    "            logits=torch.stack(batch_logits),\n",
    "            act=torch.as_tensor(batch_acts, dtype=torch.int32, device=device),\n",
    "            weights=torch.as_tensor(batch_weights, dtype=torch.float32, device=device))\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f' %\n",
    "            (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
    "    \n",
    "torch.save(model.state_dict(), 'gpt_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4fd90f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>char</th>\n",
       "      <th>balanced</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.981665</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.580757</td>\n",
       "      <td>0.416797</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=0)</td>\n",
       "      <td>((</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.484173</td>\n",
       "      <td>0.513390</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=2 n_closed=1)</td>\n",
       "      <td>(()</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.769993</td>\n",
       "      <td>0.223919</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023373</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>0.079256</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=3 n_closed=2)</td>\n",
       "      <td>(())(</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>0.557773</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())()</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040663</td>\n",
       "      <td>0.879360</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=4 n_closed=3)</td>\n",
       "      <td>(())()(</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=5 n_closed=3)</td>\n",
       "      <td>(())()((</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.369717</td>\n",
       "      <td>0.627704</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=5 n_closed=4)</td>\n",
       "      <td>(())()(()</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.470775</td>\n",
       "      <td>0.514142</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())()(())</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.268090</td>\n",
       "      <td>0.606613</td>\n",
       "      <td>0.125298</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=6 n_closed=5)</td>\n",
       "      <td>(())()(())(</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.344629</td>\n",
       "      <td>0.652772</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=7 n_closed=5)</td>\n",
       "      <td>(())()(())((</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.324011</td>\n",
       "      <td>0.673386</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=8 n_closed=5)</td>\n",
       "      <td>(())()(())(((</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.304462</td>\n",
       "      <td>0.692303</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=9 n_closed=5)</td>\n",
       "      <td>(())()(())((((</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.298783</td>\n",
       "      <td>0.698388</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=9 n_closed=6)</td>\n",
       "      <td>(())()(())(((()</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.115145</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=9 n_closed=7)</td>\n",
       "      <td>(())()(())(((())</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.808931</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=9 n_closed=8)</td>\n",
       "      <td>(())()(())(((()))</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.252470</td>\n",
       "      <td>0.135831</td>\n",
       "      <td>0.611699</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>(())()(())(((())))</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.791346</td>\n",
       "      <td>0.086134</td>\n",
       "      <td>0.122520</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.986695</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.411661</td>\n",
       "      <td>0.585405</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.008949</td>\n",
       "      <td>0.939381</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=1)</td>\n",
       "      <td>()(</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.389928</td>\n",
       "      <td>0.607603</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()()</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.017204</td>\n",
       "      <td>0.806585</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.067912</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())(</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.392927</td>\n",
       "      <td>0.603679</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())((</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.379055</td>\n",
       "      <td>0.618232</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())(()</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.836088</td>\n",
       "      <td>0.096957</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())(()(</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.373317</td>\n",
       "      <td>0.623613</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())(()()</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.256533</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.172834</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.983329</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.404758</td>\n",
       "      <td>0.592307</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.823473</td>\n",
       "      <td>0.164238</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=1)</td>\n",
       "      <td>()(</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.379797</td>\n",
       "      <td>0.617323</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>()()</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.838527</td>\n",
       "      <td>0.149910</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, 4, early close)</td>\n",
       "      <td>()())</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.874855</td>\n",
       "      <td>0.071254</td>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.987375</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=1 n_closed=0)</td>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.421254</td>\n",
       "      <td>0.575813</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=2 n_closed=0)</td>\n",
       "      <td>((</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.431444</td>\n",
       "      <td>0.565572</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=3 n_closed=0)</td>\n",
       "      <td>(((</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.420631</td>\n",
       "      <td>0.576438</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=3 n_closed=1)</td>\n",
       "      <td>((()</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.875818</td>\n",
       "      <td>0.117115</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=4 n_closed=1)</td>\n",
       "      <td>((()(</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.407781</td>\n",
       "      <td>0.589307</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=4 n_closed=2)</td>\n",
       "      <td>((()()</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.795647</td>\n",
       "      <td>0.195289</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=5 n_closed=2)</td>\n",
       "      <td>((()()(</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.400433</td>\n",
       "      <td>0.596662</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=6 n_closed=2)</td>\n",
       "      <td>((()()((</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>0.574857</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=6 n_closed=3)</td>\n",
       "      <td>((()()(()</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.381563</td>\n",
       "      <td>0.612280</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=7 n_closed=3)</td>\n",
       "      <td>((()()(()(</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.379262</td>\n",
       "      <td>0.617769</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=7 n_closed=4)</td>\n",
       "      <td>((()()(()()</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.303514</td>\n",
       "      <td>0.686644</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=7 n_closed=5)</td>\n",
       "      <td>((()()(()())</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.046593</td>\n",
       "      <td>0.430316</td>\n",
       "      <td>0.523091</td>\n",
       "      <td>(</td>\n",
       "      <td>(False, n_open=8 n_closed=5)</td>\n",
       "      <td>((()()(()())(</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.626994</td>\n",
       "      <td>)</td>\n",
       "      <td>(False, n_open=8 n_closed=6)</td>\n",
       "      <td>((()()(()())()</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         end         (         ) char                      balanced   \n",
       "0   0.002948  0.981665  0.015387    (  (False, n_open=1 n_closed=0)  \\\n",
       "1   0.002446  0.580757  0.416797    (  (False, n_open=2 n_closed=0)   \n",
       "2   0.002437  0.484173  0.513390    )  (False, n_open=2 n_closed=1)   \n",
       "3   0.006088  0.769993  0.223919    )                          True   \n",
       "4   0.023373  0.897370  0.079256    (  (False, n_open=3 n_closed=2)   \n",
       "5   0.002698  0.439528  0.557773    )                          True   \n",
       "6   0.040663  0.879360  0.079977    (  (False, n_open=4 n_closed=3)   \n",
       "7   0.002475  0.386458  0.611067    (  (False, n_open=5 n_closed=3)   \n",
       "8   0.002579  0.369717  0.627704    )  (False, n_open=5 n_closed=4)   \n",
       "9   0.015082  0.470775  0.514142    )                          True   \n",
       "10  0.268090  0.606613  0.125298    (  (False, n_open=6 n_closed=5)   \n",
       "11  0.002599  0.344629  0.652772    (  (False, n_open=7 n_closed=5)   \n",
       "12  0.002602  0.324011  0.673386    (  (False, n_open=8 n_closed=5)   \n",
       "13  0.003235  0.304462  0.692303    (  (False, n_open=9 n_closed=5)   \n",
       "14  0.002830  0.298783  0.698388    )  (False, n_open=9 n_closed=6)   \n",
       "15  0.004174  0.115145  0.880682    )  (False, n_open=9 n_closed=7)   \n",
       "16  0.071397  0.119672  0.808931    )  (False, n_open=9 n_closed=8)   \n",
       "17  0.252470  0.135831  0.611699    )                          True   \n",
       "18  0.791346  0.086134  0.122520   \\n                                 \n",
       "19  0.006942  0.986695  0.006362    (  (False, n_open=1 n_closed=0)   \n",
       "20  0.002934  0.411661  0.585405    )                          True   \n",
       "21  0.008949  0.939381  0.051670    (  (False, n_open=2 n_closed=1)   \n",
       "22  0.002469  0.389928  0.607603    )                          True   \n",
       "23  0.017204  0.806585  0.176210    )       (False, 4, early close)   \n",
       "24  0.067912  0.918954  0.013134    (       (False, 4, early close)   \n",
       "25  0.003394  0.392927  0.603679    (       (False, 4, early close)   \n",
       "26  0.002713  0.379055  0.618232    )       (False, 4, early close)   \n",
       "27  0.066955  0.836088  0.096957    (       (False, 4, early close)   \n",
       "28  0.003071  0.373317  0.623613    )       (False, 4, early close)   \n",
       "29  0.256533  0.570632  0.172834   \\n                                 \n",
       "30  0.006652  0.983329  0.010019    (  (False, n_open=1 n_closed=0)   \n",
       "31  0.002935  0.404758  0.592307    )                          True   \n",
       "32  0.012288  0.823473  0.164238    (  (False, n_open=2 n_closed=1)   \n",
       "33  0.002881  0.379797  0.617323    )                          True   \n",
       "34  0.011564  0.838527  0.149910    )       (False, 4, early close)   \n",
       "35  0.053891  0.874855  0.071254   \\n                                 \n",
       "36  0.005506  0.987375  0.007119    (  (False, n_open=1 n_closed=0)   \n",
       "37  0.002933  0.421254  0.575813    (  (False, n_open=2 n_closed=0)   \n",
       "38  0.002984  0.431444  0.565572    (  (False, n_open=3 n_closed=0)   \n",
       "39  0.002932  0.420631  0.576438    )  (False, n_open=3 n_closed=1)   \n",
       "40  0.007067  0.875818  0.117115    (  (False, n_open=4 n_closed=1)   \n",
       "41  0.002911  0.407781  0.589307    )  (False, n_open=4 n_closed=2)   \n",
       "42  0.009064  0.795647  0.195289    (  (False, n_open=5 n_closed=2)   \n",
       "43  0.002905  0.400433  0.596662    (  (False, n_open=6 n_closed=2)   \n",
       "44  0.003011  0.422133  0.574857    )  (False, n_open=6 n_closed=3)   \n",
       "45  0.006157  0.381563  0.612280    (  (False, n_open=7 n_closed=3)   \n",
       "46  0.002969  0.379262  0.617769    )  (False, n_open=7 n_closed=4)   \n",
       "47  0.009842  0.303514  0.686644    )  (False, n_open=7 n_closed=5)   \n",
       "48  0.046593  0.430316  0.523091    (  (False, n_open=8 n_closed=5)   \n",
       "49  0.002809  0.370196  0.626994    )  (False, n_open=8 n_closed=6)   \n",
       "\n",
       "                  text  len  \n",
       "0                    (    1  \n",
       "1                   ((    2  \n",
       "2                  (()    3  \n",
       "3                 (())    4  \n",
       "4                (())(    5  \n",
       "5               (())()    6  \n",
       "6              (())()(    7  \n",
       "7             (())()((    8  \n",
       "8            (())()(()    9  \n",
       "9           (())()(())   10  \n",
       "10         (())()(())(   11  \n",
       "11        (())()(())((   12  \n",
       "12       (())()(())(((   13  \n",
       "13      (())()(())((((   14  \n",
       "14     (())()(())(((()   15  \n",
       "15    (())()(())(((())   16  \n",
       "16   (())()(())(((()))   17  \n",
       "17  (())()(())(((())))   18  \n",
       "18                        0  \n",
       "19                   (    1  \n",
       "20                  ()    2  \n",
       "21                 ()(    3  \n",
       "22                ()()    4  \n",
       "23               ()())    5  \n",
       "24              ()())(    6  \n",
       "25             ()())((    7  \n",
       "26            ()())(()    8  \n",
       "27           ()())(()(    9  \n",
       "28          ()())(()()   10  \n",
       "29                        0  \n",
       "30                   (    1  \n",
       "31                  ()    2  \n",
       "32                 ()(    3  \n",
       "33                ()()    4  \n",
       "34               ()())    5  \n",
       "35                        0  \n",
       "36                   (    1  \n",
       "37                  ((    2  \n",
       "38                 (((    3  \n",
       "39                ((()    4  \n",
       "40               ((()(    5  \n",
       "41              ((()()    6  \n",
       "42             ((()()(    7  \n",
       "43            ((()()((    8  \n",
       "44           ((()()(()    9  \n",
       "45          ((()()(()(   10  \n",
       "46         ((()()(()()   11  \n",
       "47        ((()()(()())   12  \n",
       "48       ((()()(()())(   13  \n",
       "49      ((()()(()())()   14  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_as_df('gpt_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea3d5b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "(False, 2, 'early close') ())()\n",
      "True (((())))(())\n",
      "(False, 'n_open=9 n_closed=8') (()((()))()((()))\n",
      "(False, 16, 'early close') ()(()()(((())))))\n",
      "True ()()()()(()())\n",
      "(False, 'n_open=3 n_closed=2') ((())\n",
      "(False, 12, 'early close') ()(((())))()))\n",
      "(False, 'n_open=9 n_closed=8') ()(()()()()(()())\n",
      "True ()()(((())))\n",
      "True ((((()()))()))\n",
      "(False, 2, 'early close') ())()((()()\n",
      "(False, 2, 'early close') ())())()((((()))\n",
      "(False, 4, 'early close') (()))()())()\n",
      "(False, 'n_open=6 n_closed=5') ()((())()()\n",
      "(False, 16, 'early close') ((()((()))())()))\n",
      "(False, 'n_open=3 n_closed=2') (()()\n",
      "True ()((()))(()())\n",
      "True (()((()())))()((()))\n",
      "True ()()(((())))\n",
      "True ()()()()()()\n",
      "(False, 'n_open=9 n_closed=8') (()()()()(((())))\n",
      "(False, 6, 'early close') (()()))(()\n",
      "(False, 14, 'early close') ()(()((())())))))\n",
      "(False, 'n_open=3 n_closed=2') ()(()\n",
      "(False, 4, 'early close') ()())(()()()(())()\n",
      "(False, 8, 'early close') ()((())))()\n",
      "True ()()()()(()())()()\n",
      "(False, 10, 'early close') ((()()())))\n",
      "(False, 'n_open=5 n_closed=4') ()()((())\n",
      "(False, 4, 'early close') ()())()()()\n",
      "(False, 'n_open=9 n_closed=7') (()((()()()(()))\n",
      "(False, 2, 'early close') ()))()\n",
      "True ()()()()()\n",
      "True ()()(()(()()))\n",
      "True ()((()()))()\n",
      "(False, 8, 'early close') ()()()())(()((()))()\n",
      "(False, 'n_open=2 n_closed=0') ((\n"
     ]
    }
   ],
   "source": [
    "for sample in generate_sample('gpt_1.pt').split('\\n'):\n",
    "    print(_is_balanced(sample), sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78020b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
